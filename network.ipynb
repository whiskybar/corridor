{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(nn.Softmax(dim=1)(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('linear_relu_stack.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0310,  0.0208,  0.0055,  ...,  0.0110,  0.0133,  0.0091],\n",
       "          [ 0.0140,  0.0327, -0.0173,  ..., -0.0018,  0.0154, -0.0157],\n",
       "          [-0.0237,  0.0213, -0.0269,  ...,  0.0308, -0.0231,  0.0160],\n",
       "          ...,\n",
       "          [-0.0357, -0.0246,  0.0300,  ..., -0.0325,  0.0190, -0.0280],\n",
       "          [ 0.0171, -0.0111, -0.0267,  ..., -0.0070, -0.0279, -0.0292],\n",
       "          [-0.0029, -0.0185, -0.0169,  ..., -0.0157, -0.0269, -0.0294]],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('linear_relu_stack.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 2.2661e-02, -5.5666e-03, -1.4075e-02, -1.4687e-02,  1.0062e-02,\n",
       "          -3.3937e-02,  3.8157e-03,  2.5960e-02, -3.0138e-02, -1.1059e-02,\n",
       "           2.9186e-02, -2.6695e-02,  1.0879e-02, -8.4445e-03,  2.8941e-02,\n",
       "          -1.1882e-02,  7.1831e-03,  2.3959e-02,  1.8371e-02,  3.0254e-02,\n",
       "           3.0497e-02, -2.8459e-02, -1.8877e-02, -1.5487e-02, -3.5036e-02,\n",
       "           2.8933e-02,  2.1544e-02,  2.9359e-02,  1.6475e-02, -4.9973e-03,\n",
       "           2.1307e-02,  2.1863e-02, -2.8966e-02,  2.4163e-02,  3.4496e-02,\n",
       "           2.0024e-02,  1.5426e-02, -2.4557e-02,  1.4001e-02, -1.3765e-02,\n",
       "           2.6104e-02, -3.5249e-02, -2.6532e-02,  3.2339e-02, -7.9324e-04,\n",
       "           3.2354e-02, -1.7317e-02,  3.5416e-02, -1.8073e-02,  3.4592e-03,\n",
       "          -1.6764e-02, -2.6062e-02,  1.4339e-02,  9.4445e-03, -1.1203e-02,\n",
       "          -1.9744e-02,  1.0584e-02,  1.3781e-02,  2.4865e-02,  3.1451e-02,\n",
       "          -1.3920e-02, -5.2679e-03,  7.3974e-03,  1.5217e-02,  3.2390e-02,\n",
       "          -2.4073e-02, -1.7700e-02, -2.7420e-02, -2.6347e-02, -3.3190e-02,\n",
       "           3.1002e-02,  3.3278e-03,  4.9181e-03, -2.5598e-02, -7.0818e-04,\n",
       "          -1.7301e-02, -4.1934e-03,  8.5115e-03,  1.2993e-02,  1.7176e-02,\n",
       "           3.0374e-02,  1.1154e-02, -2.5213e-02, -1.6392e-02,  3.2294e-02,\n",
       "          -5.7291e-03,  3.0817e-02,  2.0890e-02,  2.0376e-02, -1.9276e-02,\n",
       "          -1.4113e-02, -2.5028e-02, -6.8517e-03,  1.2895e-02,  3.0167e-02,\n",
       "           1.0794e-02, -3.2266e-02, -6.7943e-03,  2.3029e-02, -2.6478e-02,\n",
       "          -3.3497e-02, -3.0769e-02,  2.8303e-02,  8.4820e-03,  2.5178e-02,\n",
       "          -3.0003e-02,  2.2223e-02,  3.5383e-03, -7.6107e-03,  9.7289e-03,\n",
       "          -2.7782e-02,  2.7511e-02,  3.5695e-02,  1.2902e-02,  6.6883e-03,\n",
       "          -2.2071e-02, -4.3944e-04,  3.0973e-03, -1.2953e-02,  1.8036e-02,\n",
       "          -7.2121e-03, -3.0400e-02, -1.7442e-02, -1.3174e-02,  1.8954e-02,\n",
       "          -2.8867e-02,  2.2613e-02, -3.0926e-02, -7.3962e-03,  1.3579e-03,\n",
       "           8.3510e-03, -8.1857e-03,  1.3829e-02,  3.0183e-03,  2.4110e-02,\n",
       "           2.5770e-03,  2.9720e-02, -1.7136e-02,  5.1389e-03,  1.9882e-02,\n",
       "          -2.4696e-02,  2.2502e-02, -2.1530e-02, -2.7593e-02,  2.6943e-03,\n",
       "          -2.1713e-02,  1.2835e-02, -3.3232e-02,  8.9527e-03, -1.6543e-02,\n",
       "          -1.0185e-02,  3.3321e-02, -1.2278e-02, -2.7328e-02,  6.4385e-03,\n",
       "          -2.8936e-02, -1.3168e-02, -3.1882e-02, -3.4551e-02, -3.0674e-02,\n",
       "           1.1311e-02, -2.5292e-02,  1.2476e-02, -2.6921e-02, -1.4533e-02,\n",
       "          -3.2358e-02,  1.5966e-02,  7.6673e-05,  4.0153e-03,  7.2638e-04,\n",
       "          -3.1975e-02,  2.7108e-02,  3.1052e-02, -2.5232e-02, -3.0593e-02,\n",
       "           3.5454e-02, -1.4043e-02, -2.1737e-02,  2.0144e-02,  1.9810e-02,\n",
       "           2.0897e-02,  2.2512e-02, -1.5750e-02, -7.7725e-03, -2.6758e-03,\n",
       "          -1.7751e-02, -1.7317e-02, -1.1860e-02,  1.2312e-02,  4.7980e-03,\n",
       "          -2.6640e-02,  3.1187e-02, -1.3744e-02,  2.8446e-02, -2.6806e-02,\n",
       "           3.3914e-02,  2.2763e-02,  5.1175e-03,  1.3654e-02,  1.2474e-02,\n",
       "          -1.5396e-02,  2.5491e-02, -2.0744e-02,  2.0240e-02,  1.8076e-02,\n",
       "           3.2684e-02,  9.4316e-03, -1.8446e-03,  6.7396e-03, -2.9234e-03,\n",
       "          -1.3980e-02, -1.6120e-02, -3.1739e-02, -1.5414e-02, -8.9901e-03,\n",
       "           6.6598e-03, -2.1548e-02, -1.1764e-02, -1.1329e-02, -1.1644e-02,\n",
       "           3.1876e-02, -4.3791e-03,  1.3037e-02,  4.7783e-03,  2.0527e-02,\n",
       "           1.2435e-02, -9.9239e-03, -3.2746e-03,  1.7990e-02, -3.0777e-02,\n",
       "          -1.7141e-02,  2.5923e-03,  1.7921e-02, -9.9459e-03,  1.3883e-02,\n",
       "          -3.3194e-02, -2.8859e-02,  1.0662e-02, -3.1234e-02,  2.8227e-02,\n",
       "           2.9356e-02, -2.8069e-02,  2.2739e-02, -1.9010e-03, -7.2857e-03,\n",
       "          -2.9549e-02,  2.1911e-02, -2.3847e-02,  4.6514e-03, -3.4719e-02,\n",
       "           3.1016e-02, -5.3879e-04,  1.7793e-02,  5.3857e-03, -1.3643e-03,\n",
       "           6.7055e-03, -4.4065e-06,  1.2469e-02,  3.6882e-03,  2.5642e-02,\n",
       "           1.2284e-02, -2.1885e-02, -4.8129e-03,  3.4253e-03,  1.1669e-02,\n",
       "           3.4390e-02, -2.6766e-02,  1.5389e-02, -2.3894e-02, -1.4267e-02,\n",
       "           2.4117e-03, -2.1477e-02, -1.9734e-03,  1.3236e-03,  2.5923e-02,\n",
       "           1.2639e-03, -2.0351e-02, -1.9994e-03, -2.7176e-02, -3.1504e-02,\n",
       "          -3.4309e-02, -2.1940e-03,  9.0522e-04, -5.1432e-04, -3.3323e-02,\n",
       "          -3.2127e-02,  2.3906e-02,  1.8194e-02,  3.1579e-02,  4.9538e-03,\n",
       "          -1.7497e-02,  7.2959e-04,  1.9389e-02, -2.3317e-02, -3.2752e-02,\n",
       "          -2.2272e-02,  3.2359e-02,  4.6795e-03,  3.2593e-02,  3.0944e-02,\n",
       "           3.5403e-03, -4.0657e-03, -2.3461e-02,  9.8218e-03,  2.1735e-02,\n",
       "           2.1678e-02,  3.4753e-02, -3.5470e-02,  1.4063e-02, -1.6701e-02,\n",
       "          -9.4631e-03,  2.6152e-02, -1.1562e-02,  2.5602e-02, -4.0451e-03,\n",
       "          -1.4649e-02,  1.4106e-02,  4.7060e-03, -1.9818e-02,  1.4764e-02,\n",
       "           1.6680e-03, -8.8555e-07,  9.6643e-03, -1.6623e-02,  1.5341e-02,\n",
       "          -2.0965e-02, -5.2915e-03,  1.2079e-02,  3.5479e-02, -9.6319e-03,\n",
       "           2.6071e-02, -8.7036e-03,  3.7092e-03, -5.1371e-04, -2.0270e-02,\n",
       "          -3.1108e-02, -1.7634e-04,  8.7531e-03,  5.5421e-03,  2.0727e-02,\n",
       "           2.7084e-02, -1.8079e-02,  3.4257e-02, -6.1966e-04, -3.2996e-02,\n",
       "          -2.4502e-02, -1.5002e-02,  1.2857e-02,  2.6744e-02,  2.7958e-02,\n",
       "           4.9064e-03,  1.7160e-02, -3.2563e-02, -1.5443e-02, -8.0611e-03,\n",
       "           2.9138e-02,  3.3160e-02, -3.0406e-02, -1.6577e-02,  1.3573e-02,\n",
       "          -2.0061e-02, -3.1004e-02,  1.9291e-03,  1.8234e-02,  3.1021e-03,\n",
       "           8.8651e-03, -2.2533e-02,  1.4685e-02,  1.2953e-02, -6.1686e-03,\n",
       "          -1.1897e-02,  1.6866e-02,  1.3406e-02, -2.2712e-02,  2.0854e-03,\n",
       "          -9.2821e-04,  2.6400e-02,  2.3592e-02, -1.4602e-02, -1.8043e-02,\n",
       "           3.4467e-02,  6.4226e-04,  7.7442e-03,  1.0391e-03, -1.7353e-02,\n",
       "          -5.7399e-04, -1.3103e-02,  1.5983e-02,  3.3423e-02,  2.1716e-02,\n",
       "          -2.8132e-02,  5.9593e-03, -7.8081e-03,  8.8232e-03,  1.3572e-02,\n",
       "           2.9029e-02, -5.0549e-03,  2.0009e-02,  7.1060e-03, -1.7809e-02,\n",
       "          -2.0599e-02, -1.5518e-02, -2.2777e-02,  1.3068e-02,  3.6373e-03,\n",
       "          -5.0901e-03,  1.6076e-02,  2.7722e-02, -1.1758e-03,  1.4107e-02,\n",
       "          -2.1259e-02, -1.5015e-02,  2.9841e-02, -2.2656e-02,  2.4790e-02,\n",
       "          -3.1345e-02, -1.7709e-02, -2.3747e-02, -6.5606e-04, -1.8553e-02,\n",
       "          -1.0890e-04,  1.5023e-02, -1.4045e-02, -3.0245e-02,  2.2265e-02,\n",
       "          -3.2459e-02, -2.5831e-02, -1.7315e-02,  2.7748e-02, -3.3580e-02,\n",
       "           4.4863e-04,  5.6690e-03, -3.1865e-02, -2.3849e-02, -2.7710e-02,\n",
       "          -3.2216e-03, -9.5967e-03,  2.9410e-02,  3.3951e-02, -1.9350e-02,\n",
       "          -6.6678e-03, -3.6763e-03,  2.6442e-02, -2.8750e-03,  2.2297e-02,\n",
       "          -2.6820e-02,  4.4616e-03, -2.1543e-02, -2.0217e-02, -3.1226e-02,\n",
       "           3.2649e-02, -2.6814e-02,  2.0952e-02,  3.3053e-02, -1.2072e-02,\n",
       "          -3.0070e-02,  2.2175e-02, -2.9791e-02,  2.0507e-02,  1.4484e-02,\n",
       "          -3.8430e-03, -4.1857e-03, -1.6798e-02,  1.0013e-02,  1.0396e-02,\n",
       "           2.5068e-02,  2.3489e-02, -2.2979e-02,  7.3580e-03,  2.7885e-02,\n",
       "           2.0197e-02,  1.7326e-02, -3.4517e-02, -9.4261e-03,  1.3273e-02,\n",
       "           1.3609e-02, -3.2323e-02, -6.7817e-03, -3.1210e-02, -4.0241e-04,\n",
       "           1.1086e-02,  2.5991e-03,  2.4104e-02, -1.5359e-02, -1.8784e-02,\n",
       "           2.0156e-02,  2.9882e-02,  2.9959e-02, -6.5792e-03,  1.1103e-02,\n",
       "           2.0077e-02,  1.5288e-02, -1.4768e-02,  2.0962e-02, -3.5203e-02,\n",
       "          -1.8407e-02,  9.6940e-03, -8.8238e-03,  2.6704e-02, -6.4420e-04,\n",
       "          -3.1223e-02, -2.1643e-02,  3.5005e-02, -7.6276e-03,  3.4277e-03,\n",
       "           3.1136e-02,  1.8417e-02, -7.9105e-03, -1.6893e-02, -2.2855e-02,\n",
       "           1.4138e-02,  3.0631e-02], device='cuda:0', requires_grad=True)),\n",
       " ('linear_relu_stack.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0187, -0.0064, -0.0288,  ..., -0.0350,  0.0267,  0.0130],\n",
       "          [ 0.0106, -0.0016,  0.0010,  ...,  0.0396, -0.0023, -0.0241],\n",
       "          [-0.0348,  0.0383,  0.0050,  ..., -0.0412,  0.0148,  0.0256],\n",
       "          ...,\n",
       "          [-0.0396, -0.0050, -0.0247,  ..., -0.0174,  0.0126,  0.0385],\n",
       "          [-0.0405, -0.0230,  0.0181,  ...,  0.0098, -0.0200, -0.0294],\n",
       "          [ 0.0109,  0.0369,  0.0252,  ...,  0.0050, -0.0054, -0.0297]],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('linear_relu_stack.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0136, -0.0161,  0.0263, -0.0335, -0.0065,  0.0170,  0.0019,  0.0185,\n",
       "           0.0421, -0.0241, -0.0167,  0.0411, -0.0142, -0.0322, -0.0366,  0.0093,\n",
       "           0.0243,  0.0125, -0.0106,  0.0420,  0.0422,  0.0337, -0.0364, -0.0220,\n",
       "          -0.0180,  0.0266, -0.0213,  0.0383, -0.0343, -0.0105,  0.0136, -0.0057,\n",
       "          -0.0209,  0.0064, -0.0211, -0.0054,  0.0081,  0.0115,  0.0348, -0.0441,\n",
       "           0.0100, -0.0088,  0.0340, -0.0232,  0.0240,  0.0249,  0.0046,  0.0385,\n",
       "           0.0429,  0.0165,  0.0026,  0.0330,  0.0003, -0.0034, -0.0223,  0.0145,\n",
       "          -0.0385,  0.0169, -0.0404,  0.0326, -0.0330, -0.0099, -0.0066,  0.0082,\n",
       "           0.0160, -0.0266,  0.0327, -0.0022, -0.0138,  0.0308,  0.0128,  0.0209,\n",
       "           0.0388,  0.0170, -0.0153, -0.0434, -0.0045,  0.0349,  0.0427,  0.0172,\n",
       "           0.0025,  0.0188, -0.0326,  0.0162,  0.0280,  0.0203,  0.0397, -0.0381,\n",
       "           0.0231, -0.0401, -0.0433,  0.0385,  0.0416,  0.0282,  0.0309,  0.0247,\n",
       "           0.0216,  0.0288, -0.0312,  0.0361, -0.0425,  0.0149, -0.0190, -0.0071,\n",
       "           0.0168,  0.0023, -0.0285, -0.0401,  0.0208,  0.0422,  0.0308,  0.0095,\n",
       "           0.0290, -0.0401, -0.0347, -0.0339,  0.0389,  0.0328,  0.0097, -0.0294,\n",
       "           0.0228,  0.0098, -0.0089, -0.0436,  0.0425,  0.0313,  0.0198, -0.0433,\n",
       "          -0.0001,  0.0196, -0.0352,  0.0229, -0.0235,  0.0289, -0.0105,  0.0068,\n",
       "          -0.0411,  0.0258, -0.0368,  0.0296,  0.0225, -0.0109, -0.0181,  0.0136,\n",
       "          -0.0078,  0.0278,  0.0277, -0.0428, -0.0002,  0.0234, -0.0027,  0.0008,\n",
       "           0.0255, -0.0242, -0.0107,  0.0066,  0.0032, -0.0222,  0.0106,  0.0192,\n",
       "          -0.0124,  0.0323, -0.0101, -0.0031, -0.0164, -0.0301,  0.0071, -0.0430,\n",
       "           0.0080,  0.0258, -0.0362, -0.0005,  0.0274,  0.0072, -0.0429, -0.0036,\n",
       "           0.0153, -0.0429, -0.0255, -0.0249, -0.0318, -0.0395, -0.0415, -0.0147,\n",
       "           0.0146, -0.0308,  0.0130, -0.0016,  0.0435, -0.0011, -0.0209,  0.0328,\n",
       "          -0.0339, -0.0297, -0.0075,  0.0345, -0.0173, -0.0174,  0.0247, -0.0085,\n",
       "           0.0040, -0.0219,  0.0229, -0.0214,  0.0040,  0.0137,  0.0293, -0.0149,\n",
       "           0.0387, -0.0267, -0.0347, -0.0266, -0.0141, -0.0418, -0.0219, -0.0202,\n",
       "          -0.0206,  0.0117,  0.0301,  0.0145, -0.0196, -0.0129, -0.0107, -0.0257,\n",
       "          -0.0103,  0.0419,  0.0190, -0.0410, -0.0297,  0.0081,  0.0288, -0.0211,\n",
       "          -0.0324,  0.0360, -0.0025, -0.0274, -0.0275,  0.0204, -0.0091,  0.0007,\n",
       "          -0.0404,  0.0405,  0.0270,  0.0286,  0.0173,  0.0099, -0.0276, -0.0280,\n",
       "          -0.0197,  0.0426, -0.0266,  0.0111,  0.0390, -0.0274,  0.0195, -0.0264,\n",
       "          -0.0424,  0.0419,  0.0247,  0.0159,  0.0350, -0.0219, -0.0172, -0.0006,\n",
       "          -0.0063,  0.0295, -0.0232,  0.0340, -0.0316,  0.0173,  0.0018, -0.0150,\n",
       "           0.0417, -0.0305,  0.0356,  0.0092,  0.0382,  0.0396,  0.0218,  0.0156,\n",
       "           0.0340, -0.0270,  0.0415, -0.0103, -0.0219, -0.0299,  0.0254,  0.0244,\n",
       "           0.0341,  0.0171,  0.0370, -0.0198, -0.0241,  0.0210,  0.0256,  0.0419,\n",
       "          -0.0421, -0.0427,  0.0113, -0.0028, -0.0144, -0.0279, -0.0156,  0.0383,\n",
       "           0.0150,  0.0385, -0.0254,  0.0432,  0.0302, -0.0013, -0.0435, -0.0256,\n",
       "          -0.0319, -0.0200, -0.0235,  0.0136, -0.0105,  0.0417,  0.0196,  0.0120,\n",
       "          -0.0372, -0.0002, -0.0201,  0.0415, -0.0205,  0.0128,  0.0224,  0.0241,\n",
       "           0.0421, -0.0356, -0.0423,  0.0405,  0.0427,  0.0204, -0.0079, -0.0392,\n",
       "           0.0097, -0.0386,  0.0211, -0.0381, -0.0266, -0.0058, -0.0109, -0.0436,\n",
       "          -0.0183,  0.0418, -0.0238, -0.0373, -0.0242,  0.0176,  0.0069,  0.0355,\n",
       "          -0.0369, -0.0347, -0.0129, -0.0379, -0.0247,  0.0042, -0.0141,  0.0294,\n",
       "           0.0438, -0.0361,  0.0022, -0.0115,  0.0437, -0.0298,  0.0277,  0.0310,\n",
       "          -0.0414, -0.0012,  0.0282,  0.0131,  0.0097, -0.0237,  0.0321, -0.0035,\n",
       "          -0.0292, -0.0219, -0.0316, -0.0128, -0.0309,  0.0120, -0.0196, -0.0242,\n",
       "           0.0429,  0.0070,  0.0123,  0.0049, -0.0254, -0.0266, -0.0311, -0.0255,\n",
       "          -0.0302, -0.0337,  0.0207, -0.0375,  0.0294, -0.0141,  0.0033,  0.0016,\n",
       "          -0.0201,  0.0200, -0.0364, -0.0132,  0.0023, -0.0382,  0.0070, -0.0219,\n",
       "          -0.0051,  0.0223,  0.0155, -0.0182, -0.0204, -0.0233,  0.0282,  0.0183,\n",
       "           0.0132, -0.0419, -0.0364, -0.0347,  0.0263, -0.0195,  0.0243, -0.0150,\n",
       "           0.0134, -0.0368, -0.0346, -0.0289,  0.0013,  0.0348,  0.0046,  0.0057,\n",
       "          -0.0417,  0.0409, -0.0286, -0.0138, -0.0191,  0.0015,  0.0334, -0.0325,\n",
       "          -0.0426,  0.0178,  0.0262, -0.0002,  0.0183,  0.0022,  0.0401, -0.0011,\n",
       "          -0.0368,  0.0095, -0.0326, -0.0192,  0.0127,  0.0206,  0.0440, -0.0052,\n",
       "           0.0225, -0.0317,  0.0402, -0.0368,  0.0065, -0.0229, -0.0397, -0.0290,\n",
       "          -0.0155, -0.0196,  0.0187,  0.0105,  0.0168, -0.0161, -0.0441,  0.0322,\n",
       "          -0.0143,  0.0091, -0.0438, -0.0049,  0.0400,  0.0216,  0.0241, -0.0316,\n",
       "           0.0301, -0.0182,  0.0323,  0.0097, -0.0034, -0.0066, -0.0157,  0.0274,\n",
       "          -0.0409,  0.0036,  0.0011,  0.0254, -0.0389,  0.0350, -0.0335, -0.0169,\n",
       "           0.0255, -0.0026,  0.0312, -0.0101, -0.0363, -0.0295, -0.0351, -0.0430,\n",
       "          -0.0269, -0.0245,  0.0384,  0.0262,  0.0239,  0.0008,  0.0010,  0.0142],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('linear_relu_stack.4.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0247,  0.0345, -0.0234,  ...,  0.0340,  0.0327,  0.0436],\n",
       "          [ 0.0280, -0.0184, -0.0266,  ...,  0.0361, -0.0298,  0.0356],\n",
       "          [-0.0031, -0.0370, -0.0016,  ..., -0.0356, -0.0091, -0.0354],\n",
       "          ...,\n",
       "          [-0.0032, -0.0044, -0.0248,  ..., -0.0437,  0.0137, -0.0146],\n",
       "          [ 0.0338, -0.0341, -0.0262,  ...,  0.0180, -0.0061,  0.0401],\n",
       "          [-0.0327, -0.0170,  0.0247,  ..., -0.0378,  0.0252, -0.0380]],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('linear_relu_stack.4.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0226, -0.0399, -0.0096, -0.0046, -0.0163,  0.0416,  0.0200,  0.0023,\n",
       "           0.0194,  0.0294], device='cuda:0', requires_grad=True))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corridor-LkhQS7hU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
